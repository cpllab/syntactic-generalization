#!/usr/bin/env python

import codecs
from pathlib import Path
import os
import sys

from nltk.tokenize import TreebankWordTokenizer
import torch

sys.path.append("/opt/Ordered-Neurons")
from get_raw import unkify


checkpoint_path = Path(os.environ["LMZOO_CHECKPOINT_PATH"])
vocab_path = checkpoint_path / Path(os.environ["LMZOO_VOCABULARY_PATH"])
with vocab_path.open("r", encoding="utf-8") as f:
    vocab = set(line.strip() for line in f)

tokenizer = TreebankWordTokenizer()

for line in codecs.open(sys.argv[1], encoding="utf-8"):
    tokens = tokenizer.tokenize(line.strip())
    tokens = unkify(tokens, vocab)
    print(" ".join(tokens + ["<eos>"]))
